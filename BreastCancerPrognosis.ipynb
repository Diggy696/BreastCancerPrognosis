{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from AI Labs\n",
    "Split Data before permutation importance - 70/30 split.  Can do 5 different splits\n",
    "\n",
    "When evaluating - need evaluation matrix, true positives and true negatives with false positives and false negatives\n",
    "\n",
    "Precision = True Positives/(True Positives + False Positives)\n",
    "\n",
    "Accuracy = True Positives and Negatives/(all four categories)\n",
    "\n",
    "True Positive Rate, Recall = TP/(TP+FN)\n",
    "\n",
    "False Positive Rate, FP/(FP+TN)\n",
    "\n",
    "C-index(Concordance Index) in Survival Analysis\n",
    "\n",
    "Measures the agreement between predicted risk scores and observed survival outcomes\n",
    "\n",
    "C-index = Number of concordant patient pairs/(Total comparable patient pairs)\n",
    "\n",
    "Goal of project is to maximize C-index\n",
    "\n",
    "Survival Analysis when it's binary can be random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import kagglehub - no longer needed once using local .csv file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, ShuffleSplit\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Define a scorer compatible with GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip below after first run ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/reihanenamdari/breast-cancer?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42.8k/42.8k [00:00<00:00, 1.22MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"reihanenamdari/breast-cancer\")\n",
    "path #path to data download on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Breast_Cancer.csv')\n",
    "#4000 total records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Race</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>T Stage</th>\n",
       "      <th>N Stage</th>\n",
       "      <th>6th Stage</th>\n",
       "      <th>differentiate</th>\n",
       "      <th>Grade</th>\n",
       "      <th>A Stage</th>\n",
       "      <th>Tumor Size</th>\n",
       "      <th>Estrogen Status</th>\n",
       "      <th>Progesterone Status</th>\n",
       "      <th>Regional Node Examined</th>\n",
       "      <th>Reginol Node Positive</th>\n",
       "      <th>Survival Months</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>3</td>\n",
       "      <td>Regional</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T2</td>\n",
       "      <td>N2</td>\n",
       "      <td>IIIA</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>35</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>T3</td>\n",
       "      <td>N3</td>\n",
       "      <td>IIIC</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>63</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>3</td>\n",
       "      <td>Regional</td>\n",
       "      <td>18</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T2</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIB</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>3</td>\n",
       "      <td>Regional</td>\n",
       "      <td>41</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age   Race Marital Status T Stage  N Stage 6th Stage  \\\n",
       "0   68  White        Married       T1      N1       IIA   \n",
       "1   50  White        Married       T2      N2      IIIA   \n",
       "2   58  White       Divorced       T3      N3      IIIC   \n",
       "3   58  White        Married       T1      N1       IIA   \n",
       "4   47  White        Married       T2      N1       IIB   \n",
       "\n",
       "               differentiate Grade   A Stage  Tumor Size Estrogen Status  \\\n",
       "0      Poorly differentiated     3  Regional           4        Positive   \n",
       "1  Moderately differentiated     2  Regional          35        Positive   \n",
       "2  Moderately differentiated     2  Regional          63        Positive   \n",
       "3      Poorly differentiated     3  Regional          18        Positive   \n",
       "4      Poorly differentiated     3  Regional          41        Positive   \n",
       "\n",
       "  Progesterone Status  Regional Node Examined  Reginol Node Positive  \\\n",
       "0            Positive                      24                      1   \n",
       "1            Positive                      14                      5   \n",
       "2            Positive                      14                      7   \n",
       "3            Positive                       2                      1   \n",
       "4            Positive                       3                      1   \n",
       "\n",
       "   Survival Months Status  \n",
       "0               60  Alive  \n",
       "1               62  Alive  \n",
       "2               75  Alive  \n",
       "3               84  Alive  \n",
       "4               50  Alive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create numerical columns out of Race\n",
    "df['White'] = (df['Race']=='White').astype(int)\n",
    "df['Black'] = (df['Race']=='Black').astype(int)\n",
    "df['Other'] = (df['Race']=='Other').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop categorical columns - drops Race, Marital Status, 6th stage, differentiate, A stage\n",
    "df.drop(df.columns[[1,2,5,6,8]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Categorical Columns\n",
    "df['T Stage '] = df['T Stage '].map({'T1':1,'T2':2, 'T3':3,'T4':4})\n",
    "df['N Stage'] = df['N Stage'].map({'N1':1,'N2':2, 'N3':3})\n",
    "df['Estrogen Status'] = df['Estrogen Status'].map({'Positive':1,'Negative':0})\n",
    "df['Progesterone Status'] = df['Progesterone Status'].map({'Positive': 1,'Negative': 0})\n",
    "df['Status'] = df['Status'].map({'Alive':1,'Dead':0})\n",
    "#Force to numeric and drop those with missing grades\n",
    "df['Grade'] = pd.to_numeric(df['Grade'], errors = 'coerce')\n",
    "df = df.dropna(subset = ['Grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4005, 14)\n"
     ]
    }
   ],
   "source": [
    "#check shape of dataset\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a survival object dataframe\n",
    "y = df[['Status','Survival Months']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Survival Months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Status  Survival Months\n",
       "0       1               60\n",
       "1       1               62\n",
       "2       1               75\n",
       "3       1               84\n",
       "4       1               50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below will create a list of tuples, 'Status' and 'Survival Months' by row and keeps Status boolean\n",
    "and Survival Months as a 64 bit float\n",
    "\n",
    "These two variables define survival time and status as target variables.\n",
    "\n",
    "This helps us use sckit-surival library for analysis.  It requires this tuple format.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_structured = np.array([(bool(status), months) for status, months in zip(y['Status'], y['Survival Months'])],\n",
    "                        dtype = [('Status','bool'), ('Survival Months', 'f8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( True,  60.), ( True,  62.), ( True,  75.), ..., ( True,  69.),\n",
       "       ( True,  72.), ( True, 100.)],\n",
       "      shape=(4005,), dtype=[('Status', '?'), ('Survival Months', '<f8')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_structured \n",
    "# Status of True means event happened (Death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes target columns from original dataframe, which contains our features only\n",
    "X= df.drop(columns = ['Status','Survival Months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>T Stage</th>\n",
       "      <th>N Stage</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Tumor Size</th>\n",
       "      <th>Estrogen Status</th>\n",
       "      <th>Progesterone Status</th>\n",
       "      <th>Regional Node Examined</th>\n",
       "      <th>Reginol Node Positive</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  T Stage   N Stage  Grade  Tumor Size  Estrogen Status  \\\n",
       "0   68         1        1    3.0           4                1   \n",
       "1   50         2        2    2.0          35                1   \n",
       "2   58         3        3    2.0          63                1   \n",
       "3   58         1        1    3.0          18                1   \n",
       "4   47         2        1    3.0          41                1   \n",
       "\n",
       "   Progesterone Status  Regional Node Examined  Reginol Node Positive  White  \\\n",
       "0                    1                      24                      1      1   \n",
       "1                    1                      14                      5      1   \n",
       "2                    1                      14                      7      1   \n",
       "3                    1                       2                      1      1   \n",
       "4                    1                       3                      1      1   \n",
       "\n",
       "   Black  Other  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X becomes our Independent variables\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 2403\n",
      "Number of validation samples: 801\n",
      "Number of test samples: 801\n"
     ]
    }
   ],
   "source": [
    "# --- Split data into training, validation, and test sets ---\n",
    "# First, split into training+validation and test sets (e.g., 80% train+val, 20% test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y_structured, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, split the training+validation set into training and validation sets (e.g., 60% train, 20% validation of the original data)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=(0.25), random_state=42)\n",
    "# Note: 0.25 of 0.8 is 0.2, so the final split is 60% train, 20% validation, 20% test\n",
    "\n",
    "print(f\"Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"Number of validation samples: {X_val.shape[0]}\")\n",
    "print(f\"Number of test samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Scaling (StandardScaler) ---\n",
    "#Goal is to scale the numerical features in training, test and validation data sets to prevent 'leakage' from validation and test sets into training\n",
    "#Important because it puts all features on a comparable scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom scoring function for survival analysis - closer to 1 is better.  0.5 is a random guess.  \n",
    "# C-index measures how well the model predicts who survives longer\n",
    "# Custom scoring function for survival analysis\n",
    "def cindex_score(model, x, y_struct):\n",
    "    prediction = model.predict(x)\n",
    "    return concordance_index_censored(y_struct['Status'], y_struct['Survival Months'], prediction)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Test Split - with 5 splits**\n",
    "\n",
    "Each split gets a Random Survival forest Model and evaluates each model using cindex_score, while storing and averaging the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cross-Validation C-Indices (on training data) ---\n",
      "C-Index for one split: 0.4983\n",
      "C-Index for one split: 0.4942\n",
      "C-Index for one split: 0.5012\n",
      "C-Index for one split: 0.5134\n",
      "C-Index for one split: 0.4952\n",
      "\n",
      "Average C-Index across 5 splits (on training data): 0.5005\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Cross-Validation C-Indices (on training data) ---\")\n",
    "rs = ShuffleSplit(n_splits=5, test_size=0.25, random_state=42)\n",
    "split_scores = []\n",
    "\n",
    "#Here we are training multiple models\n",
    "for train_idx, val_idx in rs.split(X_train_scaled):  # Splitting the scaled training data for cross-validation\n",
    "    X_train_fold, X_val_fold = X_train_scaled.iloc[train_idx], X_train_scaled.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    model = RandomSurvivalForest(n_estimators=100, min_samples_split=10, min_samples_leaf=15, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    c_index = cindex_score(model, X_val_fold,y_val_fold)\n",
    "    split_scores.append(c_index)\n",
    "    print(f\"C-Index for one split: {c_index:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage C-Index across 5 splits (on training data): {np.mean(split_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all models and test sets and do permutation importance for each feature then average.\n",
    "\n",
    "We shuffle the values, and model performance drop after shuffling indicates how important that feature is.\n",
    "\n",
    "We repeat 10x for each feature and we average this across the 5 CV splits.\n",
    "\n",
    "**Ultimately this helps us determine which features actually contribute to model performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Permutation importances (averaged across splits on training data):\n",
      " Estrogen Status           0.002197\n",
      "Reginol Node Positive     0.002139\n",
      "T Stage                   0.002121\n",
      "Grade                     0.001768\n",
      "White                     0.000895\n",
      "Other                     0.000659\n",
      "N Stage                  -0.000516\n",
      "Black                    -0.001442\n",
      "Progesterone Status      -0.001601\n",
      "Tumor Size               -0.003243\n",
      "Age                      -0.004102\n",
      "Regional Node Examined   -0.005902\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate average permutation importance across all splits\n",
    "importances_list = []\n",
    "\n",
    "for train_idx, val_idx in rs.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled.iloc[train_idx], X_train_scaled.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    model = RandomSurvivalForest(n_estimators=100, min_samples_split=10, min_samples_leaf=15, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    perm_result = permutation_importance(\n",
    "        estimator=model,\n",
    "        X=X_val_fold,  # Using validation fold for importance\n",
    "        y=y_val_fold,  # Using validation fold for importance\n",
    "        n_repeats=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        scoring=cindex_score\n",
    "    )\n",
    "    importances_list.append(perm_result.importances_mean)\n",
    "\n",
    "# Average the importances\n",
    "avg_importances = np.mean(importances_list, axis=0)\n",
    "importance_df = pd.Series(avg_importances, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nPermutation importances (averaged across splits on training data):\\n\", importance_df)\n",
    "\n",
    "#Positive values means model performance decrease, negative actually causing a model performance to increase\n",
    "#This means positive values are strongly predictive of survival outcomes, near 0 are not contributing to predictions and negative values may be confusing model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature and Model Selection**\n",
    "\n",
    "We do permutation based feature importance to identify top X features.  This reduces dimensionality and focuses on variables we think are more predictive.\n",
    "\n",
    "For each fold we train a full model, identify the top k most important features, train another model using only those k features and then evaluate performance.\n",
    "\n",
    "Random Survival Forest is chosen as the model approach due to its robustness with non-linear relationships and handling high dimensional data.  Random Survival Forest is good for predicting survival time distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cross-Validated Top-K Features Testing (on training data) ---\n",
      "Top 3 features average C-Index across splits (on training data): 0.5161\n",
      "Top 4 features average C-Index across splits (on training data): 0.5168\n",
      "Top 5 features average C-Index across splits (on training data): 0.5085\n",
      "Top 6 features average C-Index across splits (on training data): 0.5085\n",
      "Top 7 features average C-Index across splits (on training data): 0.5092\n",
      "Top 8 features average C-Index across splits (on training data): 0.5095\n",
      "Top 9 features average C-Index across splits (on training data): 0.5059\n",
      "Top 10 features average C-Index across splits (on training data): 0.5075\n",
      "\n",
      "Best K based on C-index (on training data): 4 with C-Index: 0.5168\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Cross-Validated Top-K Features Testing (on training data) ---\")\n",
    "\n",
    "rs_top_k = ShuffleSplit(n_splits=5, test_size=0.25, random_state=42)\n",
    "\n",
    "importances_list = []   \n",
    "all_k_scores = {}       \n",
    "best_score = 0\n",
    "best_k = 0\n",
    "\n",
    "for k in range(3, 11):\n",
    "    cindex_scores_k = []\n",
    "\n",
    "    for train_idx, val_idx in rs_top_k.split(X_train_scaled):\n",
    "        X_train_fold, X_val_fold = X_train_scaled.iloc[train_idx], X_train_scaled.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Step 1: Train full model on training fold\n",
    "        model = RandomSurvivalForest(n_estimators=100, min_samples_split=10, min_samples_leaf=15, random_state=42, n_jobs=-1)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Step 2: Permutation importance on validation fold\n",
    "        perm_result = permutation_importance(\n",
    "            estimator=model,\n",
    "            X=X_val_fold,\n",
    "            y=y_val_fold,\n",
    "            n_repeats=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            scoring=cindex_score\n",
    "        )\n",
    "        importances_list.append(perm_result.importances_mean)\n",
    "\n",
    "        # Step 3: Select top K features from the entire scaled training set based on averaged importance\n",
    "        importance_train = pd.Series(np.mean(importances_list, axis=0), index=X_train_scaled.columns)\n",
    "        top_k_features = importance_train.sort_values(ascending=False).head(k).index\n",
    "\n",
    "        # Step 4: Train new model on only Top-K features on the training fold\n",
    "        model_k = RandomSurvivalForest(n_estimators=100, min_samples_split=10, min_samples_leaf=15, random_state=42, n_jobs=-1)\n",
    "        model_k.fit(X_train_fold[top_k_features], y_train_fold)\n",
    "\n",
    "        # Step 5: Evaluate C-index on validation fold\n",
    "        c_index_k = cindex_score(model_k, X_val_fold[top_k_features], y_val_fold)\n",
    "        cindex_scores_k.append(c_index_k)\n",
    "\n",
    "    avg_cindex = np.mean(cindex_scores_k)\n",
    "    all_k_scores[k] = avg_cindex\n",
    "\n",
    "    print(f\"Top {k} features average C-Index across splits (on training data): {avg_cindex:.4f}\")\n",
    "\n",
    "    if avg_cindex > best_score:\n",
    "        best_score = avg_cindex\n",
    "        best_k = k\n",
    "print(f\"\\nBest K based on C-index (on training data): {best_k} with C-Index: {best_score:.4f}\")\n",
    "\n",
    "# Average the collected permutation importances across all runs\n",
    "avg_importances = np.mean(importances_list, axis=0)\n",
    "\n",
    "# Build importance DataFrame and select final features based on the entire scaled training set\n",
    "importance_df = pd.Series(avg_importances, index=X_train_scaled.columns).sort_values(ascending=False)\n",
    "top_features = importance_df.head(best_k).index\n",
    "\n",
    "# Final X_selected for hyperparameter tuning (using the best K features from the scaled training data)\n",
    "X_selected = X_train_scaled[top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**\n",
    "\n",
    "Simply, we look at all combinations of trees and number of features selected at each split.  This aims to optimize Concordance Index, which is a standard metric in survival analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\BreastCancerPrognosis\\AICampus\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "1080 fits failed out of a total of 6480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1080 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python\\BreastCancerPrognosis\\AICampus\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Python\\BreastCancerPrognosis\\AICampus\\Lib\\site-packages\\sksurv\\ensemble\\forest.py\", line 183, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=\"threads\")(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python\\BreastCancerPrognosis\\AICampus\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Python\\BreastCancerPrognosis\\AICampus\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python\\BreastCancerPrognosis\\AICampus\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"c:\\Python\\BreastCancerPrognosis\\AICampus\\Lib\\site-packages\\sksurv\\tree\\tree.py\", line 304, in _fit\n",
      "    params = self._check_params(n_samples)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python\\BreastCancerPrognosis\\AICampus\\Lib\\site-packages\\sksurv\\tree\\tree.py\", line 379, in _check_params\n",
      "    self._check_max_features()\n",
      "  File \"c:\\Python\\BreastCancerPrognosis\\AICampus\\Lib\\site-packages\\sksurv\\tree\\tree.py\", line 409, in _check_max_features\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Python\\BreastCancerPrognosis\\AICampus\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters from GridSearchCV: {'max_features': 1, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "def concordance_index_scorer(estimator, X, y):\n",
    "    return concordance_index_censored(y['Status'], y['Survival Months'], estimator.predict(X))[0]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100,150,200,250,300,350,400,450,500],\n",
    "    'max_features': [1, 2, 3, 4, 5,'sqrt'],\n",
    "    'min_samples_split': [3, 5,7,10,13,15],\n",
    "    'min_samples_leaf': [3,5,7,10,13,15]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomSurvivalForest(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(concordance_index_scorer),\n",
    "    cv=3, #Using folds on the scaled training data\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_selected, y_train)  # Fitting on the scaled training data with selected features\n",
    "print(\"\\nBest parameters from GridSearchCV:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Concordance Index: 0.5009\n",
      "\n",
      "Final Concordance Index on Test Set: 0.5205\n"
     ]
    }
   ],
   "source": [
    "# Train best model on the entire scaled training set with the selected features and best hyperparameters\n",
    "best_rsf = grid_search.best_estimator_\n",
    "best_rsf.fit(X_train_scaled[top_features], y_train)\n",
    "\n",
    "# Evaluate the best model on the scaled validation set\n",
    "val_c_index = concordance_index_censored(\n",
    "    event_indicator=y_val['Status'],\n",
    "    event_time=y_val['Survival Months'],\n",
    "    estimate=best_rsf.predict(X_val_scaled[top_features])\n",
    ")[0]\n",
    "\n",
    "print(f'\\nValidation Concordance Index: {val_c_index:.4f}')\n",
    "\n",
    "# --- Final Evaluation on the Scaled Test Set ---\n",
    "final_c_index_test = concordance_index_censored(\n",
    "    event_indicator=y_test['Status'],\n",
    "    event_time=y_test['Survival Months'],\n",
    "    estimate=best_rsf.predict(X_test_scaled[top_features])\n",
    ")[0]\n",
    "\n",
    "print(f'\\nFinal Concordance Index on Test Set: {final_c_index_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result interpretation**\n",
    "\n",
    "0.5: Model performs no better than random chance\n",
    "\n",
    "Greater than 0.7: Indicates good discriminative ability\n",
    "\n",
    "Greater than 0.8: Indicates strong predictive performance.  A higher C-index suggests that the model effectively distinguishes between patients with different survival outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (at 60 months on Test Set):\n",
      " [[445 322]\n",
      " [ 18  16]]\n",
      "\n",
      "True Positives (Survived beyond 60 months): 16\n",
      "True Negatives (Died within 60 months): 445\n",
      "False Positives (Predicted survived, actually died): 322\n",
      "False Negatives (Predicted died, actually survived): 18\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation Matrix (at a specific time point) on the Test Set ---\n",
    "time_horizon = 60  # Example: 60 months\n",
    "\n",
    "# Convert test set survival data to binary based on time horizon\n",
    "y_test_binary = np.array([1 if months > time_horizon and not status else 0 for status, months in y_test])\n",
    "\n",
    "# Get risk scores from your best model on the scaled test set\n",
    "risk_predictions_test = best_rsf.predict(X_test_scaled[top_features])\n",
    "\n",
    "# You'll need to determine a threshold on the risk scores to convert to binary predictions\n",
    "# This is a crucial step and can influence your results.\n",
    "# For demonstration, let's use the median risk on the validation set as a threshold\n",
    "risk_predictions_val = best_rsf.predict(X_val_scaled[top_features])\n",
    "threshold = np.median(risk_predictions_val)\n",
    "binary_predictions_test = (risk_predictions_test < threshold).astype(int) # Higher risk might mean lower survival probability\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test_binary, binary_predictions_test)\n",
    "print(\"\\nConfusion Matrix (at {} months on Test Set):\\n\".format(time_horizon), cm)\n",
    "\n",
    "# Extract TP, TN, FP, FN\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print(\"\\nTrue Positives (Survived beyond {} months):\".format(time_horizon), TP)\n",
    "print(\"True Negatives (Died within {} months):\".format(time_horizon), TN)\n",
    "print(\"False Positives (Predicted survived, actually died):\", FP)\n",
    "print(\"False Negatives (Predicted died, actually survived):\", FN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AICampus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
